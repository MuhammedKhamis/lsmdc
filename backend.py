"""backend.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10pYQAvqeRsTmD1JVJqTsdC8C5F_DkIcI
"""

'''
  Back end:
      Main function is rank_videos(link, query)
        link: link of the video
        query: query by the user
      
      Pipeline: download_video(link) -> extract_RGB() -> assemble_numpy() -> generate_csv(query) -> run_model() -> convert_ranks()
      Input: link, query
      Output: pair of periods ranks which are argmaxed to the scores: example [(1,2), (4,5), (6,7), ......]

'''


import os
os.system('pip install pytube')
import sys
stdout = sys.stdout
from pytube import YouTube
sys.stdout = stdout
os.system('pip install ipdb')
import keras
import cv2
import ipdb
import numpy as np
import pandas as pd
import skimage
from keras import models
from keras import layers
import h5py


class RETModel:

  def __init__(self):
    self.init_model()
    self.__model = self.build_model()

  def download_video(self, link):
    DEFAULT_DIR = '/content/videos'
    os.system('rm -r {}'.format(DEFAULT_DIR))
    os.system('mkdir {}'.format(DEFAULT_DIR))
    YouTube(link).streams.first().download(DEFAULT_DIR)

  def build_model(self):
    print('Building Feature Extraction Model')
    cnn = keras.applications.inception_resnet_v2.InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    model = models.Sequential()
    model.add(cnn)
    model.add(layers.AveragePooling2D(pool_size=(5, 5), strides=None, padding='valid', data_format=None))
    model.summary()
    return model

  def preprocess_frame(self, image, target_height=224, target_width=224):
    if len(image.shape) == 2:
        image = np.tile(image[:,:,None], 3)
    elif len(image.shape) == 4:
        image = image[:,:,:,0]

    image = skimage.img_as_float(image).astype(np.float32)
    height, width, rgb = image.shape
    if width == height:
        resized_image = cv2.resize(image, (target_height,target_width))

    elif height < width:
        resized_image = cv2.resize(image, (int(width * float(target_height)/height), target_width))
        cropping_length = int((resized_image.shape[1] - target_height) / 2)
        resized_image = resized_image[:,cropping_length:resized_image.shape[1] - cropping_length]

    else:
        resized_image = cv2.resize(image, (target_height, int(height * float(target_width) / width)))
        cropping_length = int((resized_image.shape[0] - target_width) / 2)
        resized_image = resized_image[cropping_length:resized_image.shape[0] - cropping_length,:]

    return cv2.resize(resized_image, (target_height, target_width))

  def extract_RGB(self, video_dir, video_save_path):
    print('Start Extraction')

    os.system('rm -r {}'.format(video_save_path))
    os.system('mkdir {}'.format(video_save_path))

    videos = os.listdir(video_dir)
    video_fullpath = os.path.join(video_dir, videos[0])
    model = self.__model

    # estimate for 10 seconds interval
    num_frames = 235
    try:
        cap  = cv2.VideoCapture(video_fullpath)
    except:
        pass

    frame_list = []
    total_frames = 0
    while True:
        ret, frame = cap.read()
        if ret is False:
            break
        
        total_frames += 1
        frame_list.append(frame)
        
        if len(frame_list) == num_frames:
          curr_frame_list = np.array(frame_list)
          cropped_frame_list = np.array(list(map(lambda x: self.preprocess_frame(x), curr_frame_list)))
          ## MAKE SURE TO RESHAPE ACCORDING TO EACH USED NET.
          feats = model.predict(cropped_frame_list)
          feats = feats.reshape(curr_frame_list.shape[0], 1536)
          video_name = 'video' + str(int(total_frames / num_frames) - 1) + '.npy'
          save_full_path = os.path.join(video_save_path, video_name)
          np.save(save_full_path, feats)
          
          frame_list = []

          
    print('Total Frames = {}'.format(total_frames))
    print('Total Videos = {}'.format(int(total_frames / num_frames)))  
    print('Finished Extraction')


  """## Assemble numpy"""

  def save_hdf5_files(self, video_df, video_id, hdf5_output_path='/content/RESNET_pool5test.hdf5'):            
    hf = h5py.File(hdf5_output_path, 'a')
    key_video_id = video_id
    if key_video_id not in hf.keys(): 
      hf.create_dataset(key_video_id, data=video_df.values)
    hf.close()

  def assemble_numpy(self, video_save_path, hdf5_dir):  
    dir_path = video_save_path
    output_file = hdf5_dir
    os.system('rm -r {}'.format(output_file))
    os.system('mkdir {}'.format(output_file))
    video_ids = os.listdir(dir_path)
    all_keys = []
    counter = 0
    for name in video_ids:
      file_path = os.path.join(dir_path, name)
      features_array = np.load(file_path)
      append_wav = False
      if append_wav:
        all_features = []
        for rgb_features in features_array:
          all_features.append(np.pad(rgb_features, (0, 128), 'constant', constant_values=0))
        # assert(np.load(output_file + name + '.npy').shape == (80, 2176))
        features_array = np.array(all_features)

      df = pd.DataFrame(data=features_array)
      video_key = name[:-4]
      all_keys.append(video_key)
      self.save_hdf5_files(video_df=df, video_id=video_key, hdf5_output_path=os.path.join(hdf5_dir, 'RESNET_pool5test.hdf5'))
      counter += 1

    print('Finished HDF5, containing {} keys'.format(counter))
    return all_keys

  """## Generate CSV"""
  
  def save_dataset_csv_file(self, output_file='/content/LSMDC16_RET_test.csv', video_keys=[], video_caption=''):                      
    os.system('rm {}'.format(output_file))
    
    all_values = []
    # construct the csv file lines
    for name in video_keys:
      # required fields
      # key description vid_key
      key = name
      description = video_caption
      data = [key, description, key]
      all_values.append(data)

    print("=" * 60)
    print('Built CSV File for Prediction, contains {} records'.format(len(all_values)))
    print("=" * 60)

    columns = ['key', 'description', 'vid_key']
    video_captions_df = pd.DataFrame(data=all_values, columns=columns)
    video_captions_df.to_csv(output_file, sep=',', header=True)
    print('Saved CSV File')
    return video_captions_df

  def generate_csv(self, query, video_keys, csv_dir):  
    output_file = csv_dir
    os.system('rm -r {}'.format(output_file))
    os.system('mkdir {}'.format(output_file))
    
    # hdf5 keys
    video_keys = video_keys
    # the query sentecne
    video_caption = query
    
    csv_df = self.save_dataset_csv_file(os.path.join(output_file, 'LSMDC16_RET_test.csv'), video_keys, video_caption)
    return csv_df

  """## Run Model

    ### Clone our repo
  """
  def init_model(self):
    os.system('rm -r lsmdc')
    os.system('git clone https://github.com/MuhammedKhamis/lsmdc.git')
    os.chdir('/content/lsmdc')
    os.system('git checkout test-inception-resnet')
    os.chdir('/content')
    print('Finished Cloning')
    
    """### Prepare the model directories for running"""

    os.system('cp -r /content/lsmdc/. /content')
    os.system('pip install -r requirements.txt')
    print('Finished installing requirements')

    os.system('mkdir /content/dataset')
    os.system('mkdir /content/dataset/LSMDC')

    """#### Copy our last checkpoint"""

    os.system('rm -r /content/checkpoint/')
    os.system('mkdir /content/checkpoint/')

    #https://drive.google.com/open?id=1-BudiyWmKPcKnsL_n6uCj-F8B0Myl5Mu
    #https://drive.google.com/open?id=1-DmTdDL0653ih7X2eegl1jYfdpk8-99I
    #https://drive.google.com/open?id=1-EqQcCKxQ079IuDDaH3gcJZBYCg6N4x_
    #https://drive.google.com/open?id=1gIvnI7a9QNWD93V6FpOl8dkr9mJtXLKv

    os.system('python download.py 1-BudiyWmKPcKnsL_n6uCj-F8B0Myl5Mu /content/checkpoint/model.ckpt-26051.data-00000-of-00001')
    os.system('python download.py 1-DmTdDL0653ih7X2eegl1jYfdpk8-99I /content/checkpoint/model.ckpt-26051.index')
    os.system('python download.py 1-EqQcCKxQ079IuDDaH3gcJZBYCg6N4x_ /content/checkpoint/model.ckpt-26051.meta')
    os.system('python download.py 1gIvnI7a9QNWD93V6FpOl8dkr9mJtXLKv /content/checkpoint/checkpoint')
    print('Finished downloading checkpoints')

    """### Prepare the necessary file by coping from lsmdc drive"""

    os.system('mkdir /content/dataset/LSMDC/Vocabulary/')
    #https://drive.google.com/open?id=1kPbyZ96chBCeKXE-8bB8vX5dfZ8oIZwI
    #https://drive.google.com/open?id=1--bjawdtNmW7B0gQmkgi-g201t5O__CB
    #https://drive.google.com/open?id=1jx7diaS2EoDC6b24RTAyfEpMVGkEsoud

    os.system('python download.py 1kPbyZ96chBCeKXE-8bB8vX5dfZ8oIZwI /content/dataset/LSMDC/Vocabulary/common_index_to_word.hkl')
    os.system('python download.py 1--bjawdtNmW7B0gQmkgi-g201t5O__CB /content/dataset/LSMDC/Vocabulary/common_word_matrix.hkl')
    os.system('python download.py 1jx7diaS2EoDC6b24RTAyfEpMVGkEsoud /content/dataset/LSMDC/Vocabulary/common_word_to_index.hkl')
    print('Finished downloading vocabulary')

  def prepare_csv(self):
    """#### Prepare CSV file"""

    os.system('mkdir /content/dataset/LSMDC/DataFrame/')
    os.system('cp -r /content/csv/LSMDC16_RET_test.csv /content/dataset/LSMDC/DataFrame/')


  def prepare_hdf5(self):
    """#### Prepare HDF5 file"""

    os.system('mkdir /content/dataset/LSMDC/LSMDC16_features')
    os.system('cp /content/hdf5/RESNET_pool5test.hdf5 /content/dataset/LSMDC/LSMDC16_features/RESNET_pool5test.hdf5')


  def test_model(self):
    os.system('python videocap/train.py > ret_model.log')


  """## Main Pipeline"""

  def rank_videos(self, link='https://www.youtube.com/watch?v=0ZZquVylLEo&feature=youtu.be', query='gun shooting'):
    # download video
    self.download_video(link)
    # divide the video
    video_dir = '/content/videos'
    video_save_path = '/content/out'
    self.extract_RGB(video_dir, video_save_path)
    # merge the npy files to hdf5 file
    hdf5_path = '/content/hdf5'
    all_keys = self.assemble_numpy(video_save_path, hdf5_path)
    # generate the csv file
    csv_path = '/content/csv'
    csv_df = self.generate_csv(query, all_keys, csv_path)
    # test model
    self.prepare_hdf5()
    self.prepare_csv()
    print('Starting Using RET Model')
    self.test_model()
